{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.MT-DNN_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPA757C/YhJdge+pyHqO8/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crux82/mt-ganbert/blob/main/1_MT_DNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL8LXzmwXd4U"
      },
      "source": [
        "# MT-DNN model in Pytorch\n",
        "This notebook shows how to train a model based only on the paradigm of the Multi-task training. The model is based on the transformer, Italian Bert-base model, UmBERTo (https://github.com/musixmatchresearch/umberto), and the MTDNN model is trained at the same time on the six tasks considered in our work,used for the recognition of abusive linguistic behaviors. The task are:\n",
        "\n",
        "1.   HaSpeeDe: Hate Spech Recognition\n",
        "2.   AMI A: Automatic Misogyny Identification (misogyny, not mysogyny)\n",
        "3.   AMI B: Automatic Misogyny Identification (misogyny_category: stereotype, sexual_harassment, discredit)\n",
        "4.   DANKMEMEs: Hate Spech Recognition in MEMEs sentences\n",
        "5.   SENTIPOLC 1: Sentiment Polarity Classification (objective, subjective)\n",
        "6.   SENTIPOLC 2: Sentiment Polarity Classification (polarity: positive, negative, neutral)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjaayC963CIW"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZs976xHuMtV"
      },
      "source": [
        "#--------------------------------\n",
        "#  Retrieve the github directory\n",
        "#--------------------------------\n",
        "!git clone https://github.com/crux82/mt-ganbert\n",
        "%cd mt-ganbert/mttransformer/\n",
        "\n",
        "#installation of necessary packages\n",
        "!pip install -r requirements.txt\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install ekphrasis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99Vna80V3Quf"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LULw5oINt9KW"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffPPXK0yOnnK"
      },
      "source": [
        "## Run training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TaSrUauaQt"
      },
      "source": [
        "For each dataset, with a dedicated script (\"script_tsv.py\"), are created 4 files:\n",
        "\n",
        "1.   taskName_task_def.yml, a config file about the task\n",
        "2.   taskName_train.tsv, file tsv of task train set \n",
        "3.   taskName_test.tsv, file tsv of task test set \n",
        "4.   taskName_dev.tsv, file tsv of task dev set \n",
        "\n",
        "\n",
        "The number of examples of train can consist of:\n",
        "\n",
        "*   All train dataset\n",
        "*   100 examples of oringinal train dataset\n",
        "*   200 examples of oringinal train dataset\n",
        "*   500 examples of oringinal train dataset\n",
        "\n",
        "\n",
        "To access to the .tsv files and config file of each task, based on the cutting of examples of the train set you want to use, these can be the paths:\n",
        "\n",
        "*   data/0/taskName_file\n",
        "*   data/100/no_gan/taskName_file\n",
        "*   data/200/no_gan/taskName_file\n",
        "*   data/500/no_gan/taskName_file\n",
        "\n",
        "\"no_gan\" means that you want to use the model based only on BERT_based model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfGXddUX2A0U"
      },
      "source": [
        "###**Tokenization and Convert to Json**\n",
        "\n",
        "The training code reads tokenized data in json format, so \"prepro_std.py\" (modified script of work https://github.com/namisan/mt-dnn) is used to do tokenization and convert data of .tsv files into json format.\n",
        "\n",
        "The args used in the script invocation are:\n",
        "\n",
        "* --model: the model used to tokenize input sentences\n",
        "* --root_dir: the folder from which to get the .tsv files\n",
        "* --task_def: the task_def file of the task, which contains useful information for converting to .json files. In this case the task_def file contains the information about all tasks\n",
        "\n",
        "The script is run for all tasks simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktE5q93Y18UV"
      },
      "source": [
        "#edit --root_dir and --task_def depending on the task and train set\n",
        "!python prepro_std.py --model Musixmatch/umberto-commoncrawl-cased-v1 --root_dir data/\"0\"/ --task_def data/0/haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162_task_def.yml  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3RCD0vM2MH4"
      },
      "source": [
        "###**Onboard your task into training!**\n",
        "\n",
        "To run the training is used the script \"train.py\" (modified script of work https://github.com/namisan/mt-dnn).\n",
        "The args used in the script invocation are:\n",
        "\n",
        "\n",
        "*   --encoder_type: it means which transformer is used to encode the sentences. In this case is equals to \"9\", that matches to UmBERTo\n",
        "*   --epochs: number of epochs that you want to use in the training\n",
        "*   --task_def: the task_def file of the tasks\n",
        "*   --data_dir: the folder from which to get the .json files\n",
        "*   --init_checkpoint: the name of the transformer to be loaded, in this case \"Musixmatch/umberto-commoncrawl-cased-v1\"\n",
        "*   --max_seq_len: the maximum length of a sequence that the BERT model can handle\n",
        "*   --batch_size: the number of training examples in one forward/backward pass\n",
        "*   --batch_size_eval: the batch size used for validation and test\n",
        "*   --optimizer: the name of optimizer that you want to use\n",
        "*   --train_datasets: the name of the tasks without train files extension, separated by \",\"\n",
        "*   --test_datasets: the name of the tasks without test files extension, , separated by \",\"\n",
        "*   --learning_rate: the learning rate that you want to use\n",
        "*   --multi_gpu_on: since the model is trained on multiple tasks at the same time, it is possible to train with multiple GPUs, to have a more timely training\n",
        "*   --grad_accumulation_step: you may need to use the gradient accumulation to make training stable, when you small GPUs. For example, if you use the flag \"--grad_accumulation_step 4\" during the training, the actual batch size will be batch_size * 4\n",
        "\n",
        "The script is run for all tasks simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4mcYjw2TyA"
      },
      "source": [
        "#edit --task_def, --data_dir, --train_datasets and test_datasets  depending on the task and train set\n",
        "!python train.py --encoder_type 9 --epochs 10 --task_def data/0/haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162_task_def.yml --data_dir data/0/musixmatch_cased/ --init_checkpoint Musixmatch/umberto-commoncrawl-cased-v1 --max_seq_len 128 --batch_size 16 --batch_size_eval 16 --optimizer \"adamW\" --train_datasets haspeede-TW,AMI2018A,AMI2018B,DANKMEMES2020,SENTIPOLC20161,SENTIPOLC20162 --test_datasets haspeede-TW,AMI2018A,AMI2018B,DANKMEMES2020,SENTIPOLC20161,SENTIPOLC20162 --learning_rate \"5e-5\" --multi_gpu_on --grad_accumulation_step 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtlhnk3cMWhB"
      },
      "source": [
        "### Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFM8b14zMZnd"
      },
      "source": [
        "**Finetune MT-DNN to each of the tasks to get task-specific models!**\n",
        "\n",
        "Use model resulting from previous training! In this case is used the script \"finetuning.py\" and the different args from the script \"train.py\" are:\n",
        "\n",
        "*   --init_checkpoint: upload the best model of previous training. The model is located in the checkpoint folder\n",
        "*   --task: to specify which task to perform finetuning for. 0 is first task.\n",
        "*   --string: the string that contains all the tasks name, separated by \"_\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byq9VL9sMXEY"
      },
      "source": [
        "#finetuning\n",
        "!python finetuning.py --finetuning --task 0 --epochs 5 --string haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162 --task_def data/0/haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162_task_def.yml --data_dir data/0/musixmatch_cased/ --init_checkpoint checkpoint/model_0.pt --max_seq_len 128 --batch_size 16 --batch_size_eval 16 --optimizer \"adamW\" --train_datasets haspeede-TW --test_datasets haspeede-TW --learning_rate \"5e-5\" --multi_gpu_on --grad_accumulation_step 4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}