{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT-GANBERT model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyND1KbT+54PXkFEQr+ieZLI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crux82/mt-ganbert/blob/master/MT_GANBERT_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kROPcbt9WhWe"
      },
      "source": [
        "# MT-GANBERT model in Pytorch\n",
        "This notebook shows how to run the MT-GANBERT model (with UmBERTo) with the example tasks present in the git repository, used for the recognition of abusive linguistic behaviors.\n",
        "\n",
        "The tasks are:\n",
        "\n",
        "\n",
        "1.   HaSpeeDe: Hate Spech Recognition\n",
        "2.   AMI A: Automatic Misogyny Identification (misogyny, not mysogyny)\n",
        "3.   AMI B: Automatic Misogyny Identification (misogyny_category: stereotype, sexual_harassment, discredit)\n",
        "4.   DANKMEMEs: Hate Spech Recognition in MEMEs sentences\n",
        "5.   SENTIPOLC 1: Sentiment Polarity Classification (objective, subjective)\n",
        "6.   SENTIPOLC 2: Sentiment Polarity Classification (polarity: positive, negative, neutral)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZs976xHuMtV",
        "outputId": "42ffe793-463f-4f5c-d57e-831f230ad8e7"
      },
      "source": [
        "!git clone --branch master https://brezzi94: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@github.com/crux82/mt-ganbert.git #modificare\n",
        "%cd mt-ganbert/mttransformer/\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install ekphrasis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mt-ganbert'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 245 (delta 84), reused 235 (delta 78), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (245/245), 4.96 MiB | 15.12 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content/mt-ganbert/mttransformer/mt-ganbert/mttransformer\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.62.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (6.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.18.43)\n",
            "Requirement already satisfied: pytorch-pretrained-bert==v0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.13)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.6.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.1.96)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: seqeval==0.0.12 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.0.12)\n",
            "Requirement already satisfied: urllib3==1.25.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.25.4)\n",
            "Requirement already satisfied: transformers==4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.23.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1->-r requirements.txt (line 2)) (2.11.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==v0.6.0->-r requirements.txt (line 6)) (1.7.1+cu101)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->-r requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 17)) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 17)) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 17)) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1->-r requirements.txt (line 17)) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==v0.6.0->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.43 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 5)) (1.21.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.43->boto3->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.43->boto3->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (8.8.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (21.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 12)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.39.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 18)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 18)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 18)) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1->-r requirements.txt (line 17)) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1->-r requirements.txt (line 17)) (7.1.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 356, in resolve\n",
            "    for key, criterion in self.state.criteria.items()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 357, in <listcomp>\n",
            "    if not self._is_current_pin_satisfying(key, criterion)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 197, in _is_current_pin_satisfying\n",
            "    for r in criterion.iter_requirement()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 197, in <genexpr>\n",
            "    for r in criterion.iter_requirement()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 170, in is_satisfied_by\n",
            "    return requirement.is_satisfied_by(candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/requirements.py\", line 109, in is_satisfied_by\n",
            "    return spec.contains(candidate.version, prereleases=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 404, in version\n",
            "    return parse_version(self.dist.version)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2678, in version\n",
            "    @property\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1619, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1424, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1621, in isEnabledFor\n",
            "    _acquireLock()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 219, in _acquireLock\n",
            "    _lock.acquire()\n",
            "KeyboardInterrupt\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu101 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu101 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (7.1.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Requirement already satisfied: ekphrasis in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.5)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (6.0.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (0.4.4)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.62.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->ekphrasis) (1.15.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/command_context.py\", line 22, in main_context\n",
            "    yield\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 524, in __exit__\n",
            "    raise exc_details[1]\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/temp_dir.py\", line 75, in tempdir_registry\n",
            "    yield _tempdir_registry\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 509, in __exit__\n",
            "    if cb(*exc_details):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 377, in _exit_wrapper\n",
            "    return cm_exit(cm, exc_type, exc, tb)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/temp_dir.py\", line 37, in global_tempdir_manager\n",
            "    _tempdir_manager = old_tempdir_manager\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 524, in __exit__\n",
            "    raise exc_details[1]\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 509, in __exit__\n",
            "    if cb(*exc_details):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 377, in _exit_wrapper\n",
            "    return cm_exit(cm, exc_type, exc, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/temp_dir.py\", line 165, in __exit__\n",
            "    self.cleanup()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/temp_dir.py\", line 184, in cleanup\n",
            "    rmtree(self._path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/tenacity/__init__.py\", line 341, in wrapped_f\n",
            "    return self(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/tenacity/__init__.py\", line 432, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/tenacity/__init__.py\", line 369, in iter\n",
            "    return fut.result()\n",
            "  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/tenacity/__init__.py\", line 435, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/misc.py\", line 135, in rmtree\n",
            "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 506, in rmtree\n",
            "    os.close(fd)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LULw5oINt9KW",
        "outputId": "8c35d11c-3cff-44bd-91d6-22a7c28602bd"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TaSrUauaQt"
      },
      "source": [
        "For each dataset, with a dedicated script (script_MT-model.py), are created 4 files:\n",
        "\n",
        "1.   taskName_task_def.yml, a config file about the task\n",
        "2.   taskName_train.tsv, file tsv of task train set \n",
        "3.   taskName_test.tsv, file tsv of task test set \n",
        "4.   taskName_dev.tsv, file tsv of task dev set \n",
        "\n",
        "\n",
        "The number of examples of train can consist of:\n",
        "\n",
        "*   All train dataset\n",
        "*   100 examples of oringinal train dataset\n",
        "*   200 examples of oringinal train dataset\n",
        "*   500 examples of oringinal train dataset\n",
        "\n",
        "\n",
        "To access the .tsv files and config file of each task, based on the cutting of examples of the train set you want to use, these can be the paths:\n",
        "\n",
        "*   data/0/taskName_file\n",
        "*   data/100/no_gan/taskName_file or data/100/gan/taskName_file\n",
        "*   data/200/no_gan/taskName_file or data/200/gan/taskName_file\n",
        "*   data/500/no_gan/taskName_file or data/500/gan/taskName_file\n",
        "\n",
        "no_gan, if the model that you want to use is BERT_based and gan if the model that you want to use is GANBERT\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfGXddUX2A0U"
      },
      "source": [
        "**Tokenization and Convert to Json**\n",
        "\n",
        "The training code reads tokenized data in json format. please use \"prepro_std.py\" to do tokenization and convert your data into json format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktE5q93Y18UV",
        "outputId": "52a706cc-0fc1-4a3c-cf66-fac1507378e4"
      },
      "source": [
        "#edit --root_dir and --task_def depending on the task and train set\n",
        "!python prepro_std.py --gan --apply_balance --model Musixmatch/umberto-commoncrawl-cased-v1 --root_dir data/\"0\"/ --task_def data/0/haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162_task_def.yml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading english - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n",
            "Reading english - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_2grams.txt\n",
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "Downloading: 100% 794k/794k [00:00<00:00, 6.73MB/s]\n",
            "Downloading: 100% 1.68M/1.68M [00:00<00:00, 10.0MB/s]\n",
            "09/17/2021 05:16:50 Task haspeede-TW\n",
            "09/17/2021 05:16:50 data/0/musixmatch_cased/haspeede-TW_train.json\n",
            "09/17/2021 05:16:50 data/0/musixmatch_cased/haspeede-TW_dev.json\n",
            "09/17/2021 05:16:51 data/0/musixmatch_cased/haspeede-TW_test.json\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3RCD0vM2MH4"
      },
      "source": [
        "**Onboard your task into training!**\n",
        "\n",
        "--encoder_type 9: it means which BERT is used to encode the sentences. In this case Umberto is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb4mcYjw2TyA",
        "outputId": "66f711a7-0b73-4f3f-f7c4-fe69a663a2f1"
      },
      "source": [
        "#edit --task_def, --data_dir, --train_datasets and test_datasets  depending on the task and train set\n",
        "!python train.py --gan --noise_size 100 --epsilon 1e-8 --encoder_type 9 --epochs 25 --task_def data/0/haspeede-TW_AMI2018A_AMI2018B_DANKMEMES2020_SENTIPOLC20161_SENTIPOLC20162_task_def.yml --data_dir data/0/musixmatch_cased/ --init_checkpoint Musixmatch/umberto-commoncrawl-cased-v1 --bert_model_type Musixmatch/umberto-commoncrawl-cased-v1 --max_seq_len 128 --batch_size 64 --batch_size_eval 64 --optimizer \"adamW\" --train_datasets haspeede-TW,AMI2018A,AMI2018B,DANKMEMES2020,SENTIPOLC20161,SENTIPOLC20162 --test_datasets haspeede-TW,AMI2018A,AMI2018B,DANKMEMES2020,SENTIPOLC20161,SENTIPOLC20162 --learning_rate \"1e-5\" #--multi_gpu_on --grad_accumulation_step 4 --fp16 --grad_clipping 0 --global_grad_clipping 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "09/17/2021 05:16:56 Launching the MT-DNN training\n",
            "09/17/2021 05:16:56 Loading data/0/musixmatch_cased/haspeede-TW_train.json as task 0\n",
            "Loaded 2400 samples out of 2400\n",
            "Loaded 600 samples out of 600\n",
            "Loaded 1000 samples out of 1000\n",
            "09/17/2021 05:16:56 ####################\n",
            "09/17/2021 05:16:56 {'log_file': 'mt-dnn-train.log', 'tensorboard': False, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'Musixmatch/umberto-commoncrawl-cased-v1', 'data_dir': 'data/0/musixmatch_cased/', 'data_sort_on': False, 'name': 'farmer', 'task_def': 'data/0/haspeede-TW_task_def.yml', 'train_datasets': ['haspeede-TW'], 'test_datasets': ['haspeede-TW'], 'glue_format_on': False, 'mkd_opt': 0, 'do_padding': False, 'gan': False, 'num_hidden_layers_d': 1, 'num_hidden_layers_g': 1, 'noise_size': 100, 'epsilon': 1e-08, 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 10, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 1, 'pooler_actf': 'tanh', 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 128, 'init_ratio': 1, 'encoder_type': 9, 'num_hidden_layers': -1, 'bert_model_type': 'Musixmatch/umberto-commoncrawl-cased-v1', 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'bin_on': False, 'bin_size': 64, 'bin_grow_ratio': 0.5, 'local_rank': -1, 'world_size': 1, 'master_addr': 'localhost', 'master_port': '6600', 'backend': 'nccl', 'cuda': True, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 10, 'batch_size': 16, 'batch_size_eval': 16, 'optimizer': 'adamW', 'grad_clipping': 0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'apply_scheduler': False, 'lr_gamma': 0.5, 'scheduler_type': 'ms', 'output_dir': 'checkpoint', 'seed': 2018, 'grad_accumulation_step': 1, 'fp16': False, 'fp16_opt_level': 'O1', 'adv_train': False, 'adv_opt': 0, 'adv_norm_level': 0, 'adv_p_norm': 'inf', 'adv_alpha': 1, 'adv_k': 1, 'adv_step_size': 1e-05, 'adv_noise_var': 1e-05, 'adv_epsilon': 1e-06, 'encode_mode': False, 'debug': False, 'task_def_list': [{'self': '{}', 'label_vocab': 'None', 'n_class': '2', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.F1MAC: 9>, <Metric.ACC: 0>)', 'split_names': \"['train', 'dev', 'test']\", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': 'None', 'adv_loss': 'None', '__class__': \"<class 'experiments.exp_def.TaskDef'>\"}]}\n",
            "09/17/2021 05:16:56 ####################\n",
            "09/17/2021 05:16:56 ############# Gradient Accumulation Info #############\n",
            "09/17/2021 05:16:56 number of step: 1500\n",
            "09/17/2021 05:16:56 number of grad grad_accumulation step: 1\n",
            "09/17/2021 05:16:56 adjusted number of step: 1500\n",
            "09/17/2021 05:16:56 ############# Gradient Accumulation Info #############\n",
            "Downloading: 100% 508/508 [00:00<00:00, 470kB/s]\n",
            "Downloading: 100% 445M/445M [00:13<00:00, 32.0MB/s]\n",
            "09/17/2021 05:17:20 \n",
            "############# Model Arch of MT-DNN #############\n",
            "SANBertNetwork(\n",
            "  (dropout_list): ModuleList(\n",
            "    (0): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (bert): CamembertModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (scoring_list): ModuleList(\n",
            "    (0): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "09/17/2021 05:17:20 Total number of params: 110623490\n",
            "09/17/2021 05:17:20 At epoch 0\n",
            "09/17/2021 05:17:20 Task [ 0] updates[     1] train loss[0.71350] remaining[0:01:10]\n",
            "09/17/2021 05:18:13 Evaluation\n",
            "Dev\n",
            "09/17/2021 05:18:17 Task haspeede-TW -- epoch 0 -- Dev F1MAC: 77.204\n",
            "09/17/2021 05:18:17 Task haspeede-TW -- epoch 0 -- Dev ACC: 78.667\n",
            "BEST F1MAC EPOCH\n",
            "BEST ACC EPOCH\n",
            "09/17/2021 05:18:17 Evaluation\n",
            "Test\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 549, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 540, in main\n",
            "    evaluation(model, args.test_datasets, test_data_list, task_defs, output_dir, epoch, with_label=True, tensorboard=tensorboard, glue_format_on=args.glue_format_on, test_on=True, device=device, logger=logger)\n",
            "  File \"train.py\", line 227, in evaluation\n",
            "    task_type=task_def.task_type)\n",
            "  File \"/content/mt-ganbert/mttransformer/mt_dnn/inference.py\", line 36, in eval_model\n",
            "    score, pred, gold = model.predict(batch_info, batch_data)\n",
            "  File \"/content/mt-ganbert/mttransformer/mt_dnn/model.py\", line 490, in predict\n",
            "    score, predict = task_obj.test_predict(score)\n",
            "  File \"/content/mt-ganbert/mttransformer/tasks/__init__.py\", line 191, in test_predict\n",
            "    score = score.data.cpu()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}